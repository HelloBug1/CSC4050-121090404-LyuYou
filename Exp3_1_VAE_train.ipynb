{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:59:29.455222Z","iopub.status.busy":"2024-04-15T01:59:29.454875Z","iopub.status.idle":"2024-04-15T01:59:34.084713Z","shell.execute_reply":"2024-04-15T01:59:34.083922Z","shell.execute_reply.started":"2024-04-15T01:59:29.455194Z"},"trusted":true},"outputs":[],"source":["from Exp3_VAE_utils import *"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:59:34.086873Z","iopub.status.busy":"2024-04-15T01:59:34.086465Z","iopub.status.idle":"2024-04-15T01:59:34.091303Z","shell.execute_reply":"2024-04-15T01:59:34.090357Z","shell.execute_reply.started":"2024-04-15T01:59:34.086848Z"},"trusted":true},"outputs":[],"source":["# Start saving checkpoints after epoch 2000\n","NUM_EPOCHS = 500\n","NUM_FOLDS = 1\n","DATA_PATH = \"data\"\n","CHECKPOINT_PATH = \"checkpoints_1\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:59:34.093262Z","iopub.status.busy":"2024-04-15T01:59:34.092465Z","iopub.status.idle":"2024-04-15T01:59:42.830792Z","shell.execute_reply":"2024-04-15T01:59:42.829914Z","shell.execute_reply.started":"2024-04-15T01:59:34.093231Z"},"trusted":true},"outputs":[],"source":["data_dir = DATA_PATH\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","data_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Pad((8, 8), fill=0, padding_mode='constant'),\n","])\n","dataset = BraTS2020Dataset(data_dir, train=True, healthy=True, transform=data_transforms)\n","\n","checkpoint_ranges = []\n","for fold_idx in range(NUM_FOLDS):\n","    checkpoint_ranges.append((0, NUM_EPOCHS))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["config = {\n","    'input_size': 256,\n","    'first_ch': 32,\n","    'latent_channels': 16,\n","    'conv1': {'kernel_size': 2, 'stride': 2, 'padding': 0}, # 256 -> 128\n","    'conv2': {'kernel_size': 2, 'stride': 2, 'padding': 0}, # 128 -> 64\n","    'conv3': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 64 -> 32\n","    'conv4': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 32 -> 16\n","    'conv5': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 16 -> 8\n","    'deconv1': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 8 -> 16\n","    'deconv2': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 16 -> 32\n","    'deconv3': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 32 -> 64\n","    'deconv4': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 64 -> 128\n","    'deconv5': {'kernel_size': 2, 'stride': 2, 'padding': 0}, # 128 -> 256\n","    'out': {'kernel_size': 3, 'stride': 1, 'padding': 1}, # 256 -> 256\n","}\n","model = Exp3VariationalAutoEncoder(config)\n","del model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:59:42.832433Z","iopub.status.busy":"2024-04-15T01:59:42.832119Z"},"trusted":true},"outputs":[],"source":["train_qr_vae_incremental_kfold(\n","    device, \n","    config,\n","    dataset,\n","    epochs=NUM_EPOCHS, \n","    train_batch_size=32,\n","    val_batch_size=271,\n","    k_fold = NUM_FOLDS,\n","    lr=3e-4,\n","    save_checkpoint=True, \n","    checkpoint_dic_path=CHECKPOINT_PATH, \n","    checkpoint_ranges=checkpoint_ranges, \n","    checkpoint_interval=1,\n","    single_transfer=False,\n","    mixed_precision=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["load_and_plot_losses(100, NUM_EPOCHS, checkpoint_dic_path=CHECKPOINT_PATH, k_fold=NUM_FOLDS)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["checkpoint_path_idx = 0\n","test_data_loader = load_dataset(data_dir, BraTS2020Dataset, train=False, healthy=True, batch_size=1)\n","sample = next(iter(test_data_loader))\n","for checkpoint_path_idx in range(NUM_FOLDS):\n","    checkpoint_path = CHECKPOINT_PATH + f'/fold_{checkpoint_path_idx}/checkpoint.pt'\n","\n","    # Load the best model\n","    checkpoint = torch.load(checkpoint_path)\n","    model = Exp3VariationalAutoEncoder(config).to(device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    \n","    (\"Model loaded from checkpoint.\")\n","\n","    # Test the model on one picture\n","    model.eval()\n","    with torch.no_grad():\n","        test_data = sample['image'].to(device)\n","        (q1, q2), mu, logvar = model(test_data)\n","        # Plot the original image\n","        plt.figure(figsize=(10, 6))\n","        plt.subplot(1, 3, 1)\n","        plt.title(\"Original\")\n","        # show the first channel of the image\n","        first_channel = test_data.cpu().numpy().squeeze()[0]\n","        plt.imshow(first_channel, cmap='gray')\n","        # Plot the reconstructed image\n","        plt.subplot(1, 3, 2)\n","        plt.title(\"Reconstruction (0.15 quantile)\")\n","        first_channel = q1.cpu().numpy().squeeze()[0]\n","        plt.imshow(first_channel, cmap='gray')\n","        # Plot the reconstructed image\n","        plt.subplot(1, 3, 3)\n","        plt.title(\"Reconstruction (median)\")\n","        first_channel = q2.cpu().numpy().squeeze()[0]\n","        plt.imshow(first_channel, cmap='gray')\n","        plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def test_qr_vae(device, model, test_loader, output_size=(256, 256), healthy=True, threshold=0.05):\n","    model.eval()\n","    rejection_rates = []\n","    true_positives, actual_positives = 0, 0  # Initialize counters for unhealthy mode\n","    false_positive, actual_negatives = 0, 0  # Initialize counters for healthy mode\n","\n","    # Iterate through the test data\n","    for data in test_loader:\n","        images = data['image'].to(device)\n","        \n","        with torch.no_grad():\n","            recon_batch, _, _ = model(images)\n","            mean_recon = recon_batch[1]\n","            std_recon = mean_recon - recon_batch[0]  # Standard deviation approximation\n","            std_recon = torch.where(std_recon == 0, torch.tensor(1e-8), std_recon)\n","            reject = calculate_rejection_mask(images, mean_recon, std_recon, output_size, threshold=0.05).astype(bool)\n","            print(f\"Size of reject: {reject.shape}\")\n","\n","        if not healthy:\n","            masks = data['mask'].numpy().astype(bool)  # Ensure boolean type for accuracy calculation\n","            masks.reshape(masks.shape[0], masks.shape[2], masks.shape[3])\n","            print(f\"Shape of masks: {masks.shape}\")\n","            \n","            # Calculate true positives and actual positives\n","            true_positives += np.sum(masks & reject)  # Intersection of truth and prediction\n","            actual_positives += np.sum(masks)\n","            false_positive += np.sum(~masks & reject)\n","            actual_negatives += np.sum(~masks)\n","        else:\n","            rejection_rate = np.mean(reject)\n","            rejection_rates.append(rejection_rate)\n","\n","    if not healthy:\n","        average_metric = true_positives / actual_positives if actual_positives > 0 else 0\n","        print(f\"True positive rate for unhealthy data: {average_metric:.4f}\")\n","        false_positive_rate = false_positive / actual_negatives if actual_negatives > 0 else 0\n","        print(f\"False positive rate for healthy data: {false_positive_rate:.4f}\")\n","    else:\n","        average_metric = np.mean(rejection_rates)\n","        print(f\"Average rejection rate for healthy data: {average_metric:.4f}\")\n","\n","    return average_metric\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_dir = DATA_PATH\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","healthy_test_loader = load_dataset(data_dir, BraTS2020Dataset, train=False, healthy=True, batch_size=1024)\n","unhealthy_test_loader = load_dataset(data_dir, BraTS2020Dataset, train=False, healthy=False, batch_size=1024)\n","for checkpoint_path_idx in range(NUM_FOLDS):\n","    print(f\"Fold {checkpoint_path_idx}\")\n","    checkpoint_path = CHECKPOINT_PATH + f'/fold_{checkpoint_path_idx}/checkpoint.pt'\n","\n","    # Load the best model\n","    checkpoint = torch.load(checkpoint_path)\n","    model = Exp3VariationalAutoEncoder(config).to(device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    \n","    (\"Model loaded from checkpoint.\")\n","    test_qr_vae(device, model, healthy_test_loader, healthy=True)\n","    test_qr_vae(device, model, unhealthy_test_loader, healthy=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["checkpoint_path_idx = 0\n","test_data_loader = load_dataset(data_dir, BraTS2020Dataset, train=False, healthy=False, batch_size=1, shuffle=True)\n","sample = next(iter(test_data_loader))\n","for checkpoint_path_idx in range(NUM_FOLDS):\n","    checkpoint_path = CHECKPOINT_PATH + f'/fold_{checkpoint_path_idx}/checkpoint.pt'\n","\n","    # Load the best model\n","    checkpoint = torch.load(checkpoint_path)\n","    model = Exp3VariationalAutoEncoder(config).to(device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    \n","    (\"Model loaded from checkpoint.\")\n","\n","    # Test the model on one picture\n","    model.eval()\n","    with torch.no_grad():\n","        test_data = sample['image'].to(device)\n","        (q1, q2), mu, logvar = model(test_data)\n","        # Plot the original image\n","        plt.figure(figsize=(10, 6))\n","        plt.subplot(2, 4, 1)\n","        plt.title(\"Original Channel 1\")\n","        # show the first channel of the image\n","        first_channel = test_data.cpu().numpy()[0, 0]\n","        plt.imshow(first_channel, cmap='gray')\n","        # Plot the ground truth mask\n","        plt.subplot(2, 4, 2)\n","        plt.title(\"Ground Truth Mask\")\n","        mask = sample['mask'].numpy()[0, 0]\n","        plt.imshow(mask, cmap='gray')\n","        # Plot the reconstruction\n","        plt.subplot(2, 4, 3)\n","        plt.title(\"Reconstruction\")\n","        plt.imshow(q2.cpu()[0, 0], cmap='gray')\n","        # Plot the rejection mask\n","        plt.subplot(2, 4, 4)\n","        plt.title(\"Rejection Mask\")\n","        reject_mask = calculate_rejection_mask(test_data, q2, q2 - q1, (256, 256))[0].squeeze()\n","        plt.imshow(reject_mask, cmap='gray')\n","        # Plot the original image\n","        plt.subplot(2, 4, 5)\n","        plt.title(\"Original Channel 2\")\n","        # show the second channel of the image\n","        second_channel = test_data.cpu().numpy()[0, 1]\n","        plt.imshow(second_channel, cmap='gray')\n","        # Plot the original image\n","        plt.subplot(2, 4, 6)\n","        plt.title(\"Original Channel 3\")\n","        # show the third channel of the image\n","        third_channel = test_data.cpu().numpy()[0, 2]\n","        plt.imshow(third_channel, cmap='gray')\n","        # Plot the reconstruction\n","        plt.subplot(2, 4, 7)\n","        plt.imshow(q1.cpu()[0, 0], cmap='gray')\n","\n","        \n","        "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4791322,"sourceId":8110965,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
