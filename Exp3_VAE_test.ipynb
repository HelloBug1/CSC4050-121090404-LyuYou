{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from Exp3_VAE_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "MODEL_PATH = \"models/VAE.pt\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size': 256,\n",
    "    'first_ch': 32,\n",
    "    'latent_channels': 40,\n",
    "    'conv1': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 256 -> 128\n",
    "    'conv2': {'kernel_size': 2, 'stride': 2, 'padding': 0}, # 128 -> 64\n",
    "    'conv3': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 64 -> 32\n",
    "    'conv4': {'kernel_size': 3, 'stride': 1, 'padding': 1}, # 32 -> 16\n",
    "    'conv5': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 16 -> 8\n",
    "    'deconv1': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 8 -> 16\n",
    "    'deconv2': {'kernel_size': 3, 'stride': 1, 'padding': 1}, # 16 -> 32\n",
    "    'deconv3': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 32 -> 64\n",
    "    'deconv4': {'kernel_size': 4, 'stride': 2, 'padding': 1}, # 64 -> 128\n",
    "    'deconv5': {'kernel_size': 2, 'stride': 2, 'padding': 0}, # 128 -> 256\n",
    "    'out': {'kernel_size': 3, 'stride': 1, 'padding': 1}, # 256 -> 256\n",
    "}\n",
    "model = Exp3VariationalAutoEncoder(config)\n",
    "model.load_state_dict(torch.load(MODEL_PATH)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_idx = 0\n",
    "test_data_loader = load_dataset(DATA_PATH, BraTS2020Dataset, train=False, healthy=False, batch_size=1, shuffle=False)\n",
    "\n",
    "(\"Model loaded from checkpoint.\")\n",
    "\n",
    "image_index_to_save = [0, 1, 6, 16, 18, 27, 28]\n",
    "# Test the model on one picture\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "for i, sample in enumerate(test_data_loader):\n",
    "    if i == 30:\n",
    "        break\n",
    "    with torch.no_grad():\n",
    "        test_data = sample['image'].to(DEVICE)\n",
    "        (q1, q2), mu, logvar = model(test_data)\n",
    "        # Plot the original image\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(2, 4, 1)\n",
    "        # Add a title for all the plots\n",
    "        plt.suptitle(\"Model Evaluation on Sample {}\".format(i))\n",
    "        plt.title(\"Original Channel 1\")\n",
    "        # show the first channel of the image\n",
    "        first_channel = test_data.cpu().numpy()[0, 0]\n",
    "        plt.imshow(first_channel, cmap='gray')\n",
    "        # Plot the ground truth mask\n",
    "        plt.subplot(2, 4, 2)\n",
    "        plt.title(\"Ground Truth Mask\")\n",
    "        mask = sample['mask'].numpy()[0, 0]\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        # Plot the reconstruction\n",
    "        plt.subplot(2, 4, 3)\n",
    "        plt.title(\"Reconstruction\")\n",
    "        plt.imshow(q2.cpu()[0, 0], cmap='gray')\n",
    "        # Plot the rejection mask\n",
    "        plt.subplot(2, 4, 4)\n",
    "        plt.title(\"Rejection Mask\")\n",
    "        reject_mask = calculate_rejection_mask(test_data, q2, q2 - q1, threshold=0.05)[0].squeeze()\n",
    "        plt.imshow(reject_mask, cmap='gray')\n",
    "        # Plot the original image\n",
    "        plt.subplot(2, 4, 5)\n",
    "        plt.title(\"Original Channel 2\")\n",
    "        # show the second channel of the image\n",
    "        second_channel = test_data.cpu().numpy()[0, 1]\n",
    "        plt.imshow(second_channel, cmap='gray')\n",
    "        # Plot the original image\n",
    "        plt.subplot(2, 4, 6)\n",
    "        plt.title(\"Original Channel 3\")\n",
    "        # show the third channel of the image\n",
    "        third_channel = test_data.cpu().numpy()[0, 2]\n",
    "        plt.imshow(third_channel, cmap='gray')\n",
    "        # Plot the reconstruction\n",
    "        plt.subplot(2, 4, 7)\n",
    "        plt.imshow(q1.cpu()[0, 0], cmap='gray')\n",
    "\n",
    "        # Save the image if it is in the list\n",
    "        if i in image_index_to_save:\n",
    "            pic_to_save = sample[\"image\"]\n",
    "            print(pic_to_save.shape)\n",
    "            pic_to_save = pic_to_save.cpu().squeeze().numpy().transpose(1, 2, 0)\n",
    "            # Save each channel as a separate image losslessly\n",
    "            for j in range(3):\n",
    "                plt.imsave(f\"pictures/sample_{i}_channel_{j}.png\", pic_to_save[:, :, j], cmap='gray')\n",
    "        # Save the ground truth mask\n",
    "        if i in image_index_to_save:\n",
    "            mask_to_save = sample[\"mask\"]\n",
    "            mask_to_save = mask_to_save.cpu().squeeze().numpy()\n",
    "            plt.imsave(f\"pictures/mask_{i}.png\", mask_to_save, cmap='gray')\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved images and test the model on them\n",
    "for i in image_index_to_save:\n",
    "    image = np.zeros((3, 256, 256))\n",
    "    for j in range(3):\n",
    "        image_to_be_loaded = plt.imread(f\"pictures/sample_{i}_channel_{j}.png\")\n",
    "        # Turn the image from 4 channels to 1\n",
    "        image[j] = image_to_be_loaded[:, :, 0]\n",
    "    image = torch.tensor(image).unsqueeze(0).float().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        (q1, q2), mu, logvar = model(image)\n",
    "        # Plot the original image\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(2, 4, 1)\n",
    "        # Add a title for all the plots\n",
    "        plt.suptitle(\"Model Evaluation on Sample {}\".format(i))\n",
    "        plt.title(\"Original Channel 1\")\n",
    "        # show the first channel of the image\n",
    "        first_channel = image.cpu().numpy()[0, 0]\n",
    "        plt.imshow(first_channel, cmap='gray')\n",
    "        # Plot the ground truth mask\n",
    "        plt.subplot(2, 4, 2)\n",
    "        plt.title(\"Ground Truth Mask\")\n",
    "        mask = plt.imread(f\"pictures/mask_{i}.png\")\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        # Plot the reconstruction\n",
    "        plt.subplot(2, 4, 3)\n",
    "        plt.title(\"Reconstruction\")\n",
    "        plt.imshow(q2.cpu()[0, 0], cmap='gray')\n",
    "        # Plot the rejection mask\n",
    "        plt.subplot(2, 4, 4)\n",
    "        plt.title(\"Rejection Mask\")\n",
    "        reject_mask = calculate_rejection_mask(image, q2, q2 - q1, threshold=0.02)[0].squeeze()\n",
    "        plt.imshow(reject_mask, cmap='gray')\n",
    "        # Plot the original image\n",
    "        plt.subplot(2, 4, 5)\n",
    "        plt.title(\"Original Channel 2\")\n",
    "        # show the second channel of the image\n",
    "        second_channel = image.cpu().numpy()[0, 1]\n",
    "        plt.imshow(second_channel, cmap='gray')\n",
    "        # Plot the original image\n",
    "        plt.subplot(2, 4, 6)\n",
    "        plt.title(\"Original Channel 3\")\n",
    "        # show the third channel of the image\n",
    "        third_channel = image.cpu().numpy()[0, 2]\n",
    "        plt.imshow(third_channel, cmap='gray')\n",
    "        # Plot the reconstruction\n",
    "        plt.subplot(2, 4, 7)\n",
    "        plt.imshow(q1.cpu()[0, 0], cmap='gray')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_qr_vae(device, model, h_test_loader, uh_test_loader, num_thresholds=20):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Generate a list of thresholds from 0 to 1\n",
    "    thresholds = np.linspace(0, 0.985, num=num_thresholds)\n",
    "\n",
    "    def cal_tpr_fpr(mask, image, mean_recon, std_recon, thresholds):\n",
    "        tprs = np.zeros_like(thresholds)\n",
    "        fprs = np.zeros_like(thresholds)\n",
    "        for i, threshold in enumerate(tqdm(thresholds)):\n",
    "            label = calculate_rejection_mask(image, mean_recon, std_recon, threshold=threshold)\n",
    "            # print(f\"Label: {label.shape}\")\n",
    "            label = label.flatten()\n",
    "            tp = np.sum(mask & label)\n",
    "            fp = np.sum(~mask & label)\n",
    "            tn = np.sum(~mask & ~label)\n",
    "            fn = np.sum(mask & ~label)\n",
    "            if tp + fn == 0:\n",
    "                tpr = 1\n",
    "            else:\n",
    "                tpr = tp / (tp + fn)\n",
    "            if fp + tn == 0:\n",
    "                fpr = 1\n",
    "            else:\n",
    "                fpr = fp / (fp + tn)\n",
    "            tprs[i] += tpr\n",
    "            fprs[i] += fpr\n",
    "            # print(f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}, TPR: {tpr}, FPR: {fpr}\")\n",
    "        return tprs, fprs\n",
    "\n",
    "    data = next(iter(h_test_loader))\n",
    "    images = data['image'].to(device)\n",
    "    masks = np.zeros(images.shape[0]*256*256, dtype=bool)\n",
    "    length = images.shape[0]\n",
    "    print(f\"Length: {length}\")\n",
    "    with torch.no_grad():\n",
    "        recon, _, _ = model(images)\n",
    "        mean_recon = recon[1]\n",
    "        std_recon = mean_recon - recon[0]\n",
    "\n",
    "        tprs_1, fprs_1 = cal_tpr_fpr(masks, images, mean_recon, std_recon, thresholds)\n",
    "        \n",
    "\n",
    "    data = next(iter(uh_test_loader))\n",
    "    images = data['image'].to(device)\n",
    "    \n",
    "    # Assuming 'mask' indicates unhealthy regions\n",
    "    masks = data['mask'].numpy().flatten()\n",
    "    length += images.shape[0]\n",
    "    print(f\"Length: {length}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        recon, _, _ = model(images)\n",
    "        mean_recon = recon[1]\n",
    "        std_recon = mean_recon - recon[0]\n",
    "\n",
    "        tprs_2, fprs_2 = cal_tpr_fpr(masks, images, mean_recon, std_recon, thresholds)\n",
    "\n",
    "    return (tprs_1 + tprs_2) / 2, (fprs_1 + fprs_2) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_test_loader = load_dataset(DATA_PATH, BraTS2020Dataset, train=False, healthy=True, batch_size=128)\n",
    "uh_test_loader = load_dataset(DATA_PATH, BraTS2020Dataset, train=False, healthy=False, batch_size=128)\n",
    "tprs, fprs = test_qr_vae(DEVICE, model, h_test_loader, uh_test_loader)\n",
    "auc_val = auc(fprs, tprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"fprs: {fprs}, tprs: {tprs}, auc: {auc_val}\")\n",
    "# Plotting the ROC Curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fprs, tprs, color='darkorange',\n",
    "            lw=lw, label='ROC curve (area = %0.2f)' % auc_val)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic across all data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
